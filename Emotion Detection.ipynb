{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd04a38-ac8d-4f0e-9817-3c76801d9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emotion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3951b73-9197-4a3a-98ba-27a74e4d9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e56c22-b111-42d1-a475-2f0e1a4e33dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import cv2\n",
    "import random\n",
    "import os \n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense,Input,Flatten,Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization,Activation,MaxPooling2D\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from IPython.display import SVG,Image\n",
    "import tensorflow as tf\n",
    "print(\"tensorflow version:\",tf.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10e80b8-f01e-4a8d-8d07-56f055e32119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc81978-33a9-40b8-a39c-d93760391777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc31567d-2221-4b55-9d7b-63601b5e166d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m images\u001b[38;5;241m-\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/ASUS/Desktop/Face detector/train/**/**\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m9\u001b[39m):\n\u001b[0;32m      3\u001b[0m     image\u001b[38;5;241m=\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(images)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "images-glob(\"C:/Users/ASUS/Desktop/Face detector/train/**/**\")\n",
    "for i in range(9):\n",
    "    image=random.choice(images)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(331+1)\n",
    "    plt.imshow(cv2.imread(image));plt.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d55929f-ae12-4db4-af70-22d7b92fc2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
